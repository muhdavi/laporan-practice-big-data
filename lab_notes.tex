%%% Laboratory	 Notes
%%% Template by Mikhail Klassen, April 2013
%%% Contributions from Sarah Mount, May 2014
%%% Updated by Muhammad Davi, September 2022
\documentclass[a4paper]{tufte-handout}
\usepackage{lab_notes}

\title{Practice Big Data}
\date{2022}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{projects}
	\begin{description}
		\item [Muhammad Davi, S.Kom., M.Cs.] adalah sebagai dosen pengampu matakuliah practice big data\footnote{Dosen Prodi Teknologi Rekayasa Komputer Jaringan, Jurusan Teknologi Informasi dan Komputer, Politeknik Negeri Lhokseumawe}.
		\item [Peserta dan Kelompok] matakuliah practice big data adalah sebegai berikut:

\begin{table}[!ht]
\caption{Peserta dan Kelompok Matakuliah Practice Big Bata}
\label{tab:peserta}
\centering
\begin{tabular}{ll} 
\toprule
Nama &	Akun Github\\
\midrule
Kelompok 1\\
\midrule
Nadzura Kumaira			& \url{https://github.com/NadzuraKumaira} \\
Nurani Harum Fardaniah	& \url{https://github.com/fardaniahnh} \\
Nuraula Tafiza			& \url{https://github.com/olala17} \\
Nurul Aflah				& \url{https://github.com/Nurulaflahhh} \\
Faiza Yuwafiqi			& \url{https://github.com/faizayuwafiqi} \\
\midrule
Kelompok 2\\
\midrule
Adinda Awaliah			& \url{https://github.com/AdindaAwaliah} \\
Adjie Yusmunandar		& \url{https://github.com/AdjieYusmunandar} \\
Arya Saputra			& \url{https://github.com/AryaSpt} \\
Jihan Dwi Sarah			& \url{https://github.com/jhndsrh} \\
\midrule
Kelompok 3\\
\midrule
Muhammad Munawir		& \url{https://github.com/Munawir027} \\
Muhammad Ikrammullah	& \url{https://github.com/Ikram160302} \\
M. Ikhsan				& \url{https://github.com/Muhammadikhsandev} \\
Zulfahmi				& \url{https://github.com/zulfahmidev} \\
\midrule
Kelompok 4\\
\midrule
Salsabila Irmanda		& \url{https://github.com/salsabilairmanda17} \\
\textcolor{red}{Siti Hajar Al Zahra	}	& - \\
Syarfani Akbar			& \url{https://github.com/SyarfaniAkbar} \\
Cut Opy Mandalisa		& \url{https://github.com/cutopymdl} \\
\midrule
Kelompok 5\\
\midrule
Rauzatinur Syah			& \url{https://github.com/rauzatinursyah} \\
Resha Russita			& \url{https://github.com/resharussita} \\
Rizki Ilhami			& \url{https://github.com/RIZKIINC} \\
Taravia Fauzah			& \url{https://github.com/traviafzah} \\
\midrule
\end{tabular}
\end{table}
	\end{description}
\end{projects}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{maybe}
    \begin{itemize}
    	\item Waktu, Tempat dan Penilaian Matakuliah Practice Big Data
    	\begin{itemize}
    	\item Waktu: 13.30 - 16.00, 16.20 - 18.00\footnote{Istirahat dan Sholat Ashar 20 Menit}
    	\item Tempat: Ruang Lab 3\footnote{Lab Jaringan dan Multimedia di Lantai Dasar Gedung Utama}
    	\item Penilaian\footnote{Sesuai ketentuan dari Kepala Lab}
    	\begin{itemize}
    	\item Responsi Kompetensi
    	\item Sikap
    	\item Laporan
    	\item Seminar
    	\item UAS
    	\item Hasil/Benda kerja
    	\end{itemize}
    	\end{itemize}
    	\item Sebelum masuk lab wajib berbaris dan berdo'a terlebih dahulu di depan lab.
    	\item Sebelum perkuliahan dimulai, mahasiswa atau yang mewakili memberi laporan.
    	\item Setiap keluar lab meminta izin kepada dosen pengampu.
    	\item Mengikuti Tata Tertib yang berlaku.
    	\item Referensi
    	\begin{itemize}
    		\item Buku Ajar Big Data \citep{Mursyidah2020}.
    	\end{itemize}
    \end{itemize}
\end{maybe}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newday{\#1 - 8 September 2022}

\newthought{Introduction \& Preparation}

Pada pertemuan pertama, kegiatan lab adalah perkenalan dan persiapan kebutuhan untuk praktik big data. Setelah dosen pengampu memperkenalkan diri dan matakuliah yang diajarkan, dilanjutkan perkenalan dari setiap mahasiswa dah hasilnya dapat dilihat pada Tabel \ref{tab:perkenalan}.

\begin{table}[!ht]
\vspace*{.5cm}
\caption{Hasil Perkenalan Mahasiswa}
\label{tab:perkenalan}
\centering
\begin{tabular}{cllr} 
\toprule
No & Nama 					& Asal Sekolah 			& Alamat\\
\midrule
1 & Adinda Awaliah			& SMA N 1 Lhokseumawe 	& Cunda \\
2 & Adjie Yusmunandar		& & \\
3 & Arya Saputra			& & \\
4 & Cut Opy Mandalisa		& SMA N 1 Syamtali Bayu	& Bayu \\
5 & Faiza Yuwafiqi			& & \\
6 & Jihan Dwi Sarah			& SMA N 1 Lhokseumawe 	& Panggoi \\
7 & M. Ikhsan				& SMK N 1 Simpang Kiri 	& Subulussalam \\
\midrule
8 & Muhammad Ikrammullah	& & \\
9 & Muhammad Munawir		& SMK N 1 Lhoksukon		& Karing Meurah Mulia \\
10 & Nadzura Kumaira		& SMK N 2 Lhokseumawe 	& Keude Aceh \\
11 & Nurani Harum Fardaniah	& SMK N 1 Lhoksukon 	& Buket Hagu \\
12 & Nuraula Tafiza			& SMK N 1 Lhoksukon 	& Alue Buket \\
13 & Nurul Aflah			& & \\
14 & Rauzatinur Syah		& MAS Misbahul Ulum 	& Geudong \\
\midrule
15 & Resha Russita			& SMA N 1 Lhokseumawe 	& Alue Awe \\
16 & Rizki Ilhami			& SMK N 1 Lhoksukon 	& Lapang \\
17 & Salsabila Irmanda		& MAS Misbahul Ulum 	& Alue Awee \\
18 & Siti Hajar Al Zahra	& & \\
19 & Syarfani Akbar			& & \\
20 & Taravia Fauzah			& SMA N 1 Dewantara 	& Blang Naleung Mameh \\
21 & Zulfahmi				& SMK N 1 Lhokseumawe	& Kuta Makmur \\
\bottomrule
\end{tabular}
\end{table}

Setelah perkenalan, setiap mahasiswa membuat akun github dan akun discord sebagai media komunikasi dan tempat bekerja secara berkelompok. Hasil dari kegiatan tersebut dapat dilihat pada Tabel \ref{tab:peserta} dan Server Discord pada alamat \url{https://discord.gg/V32EWUx6}.

Tugas di pertemuan pertama adalah menyiapkan \textit{environment} untuk tempat kerja minimal sebagai berikut:
\vspace*{-.3cm}
\begin{itemize}
\setlength\itemsep{0em}
\item \textit{Operating System}: Ubuntu 22.04 LTS
\item Processor 2 GHz dual-core
\item RAM sebesar 4 GB
\item Harddisk kosong 25 GB
\item Resolusi layar 1024 x 768
\end{itemize}
\vspace*{-.3cm}
\hrulefill

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newday{\#2 - 15 September 2022}

\newthought{Instalasi Apache Hadoop}

Pada pertemuan kedua ini kegiatan yang dilakukan adalah menginstall Apache Hadoop pada \textit{environment} yang telah dibuat pada pertemuan sebelumnya. Untuk menginstall Apache Hadoop dapat mengikut langkah-langkah berikut ini:

\begin{enumerate}
\item Install Java \\
{\tt sudo apt update} \\
{\tt sudo apt install openjdk-8-jdk -y} \\

\item Verifikasi Hasil Instalasi Java \\
{\tt java -version} \\
Jika instalasi java berhasil tanpa ada bug atau error maka akan menampilkan hasil seperti pada Gambar \ref{gam:java-version}.
\begin{figure}
\includegraphics[width=\textwidth]{java-version}
\caption{Versi Java yang Terinstall}
\label{gam:java-version}
\end{figure}

\item Download Apache Hadoop \\
{\tt wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz}

\item Ekstrak Apache Hadoop \\
{\tt tar -xzvf hadoop-3.3.4.tar.gz }
\begin{itemize}
\item x $\Rightarrow$ ekstrak file arsip.
\item z $\Rightarrow$ filter file arsip melalui gzip.
\item v $\Rightarrow$ menampilkan proses.
\item f $\Rightarrow$ nama file arsip.
\end{itemize}

\item Pindahkan hasil ekstrak ke /usr/local/ \\
{\tt sudo mv hadoop-3.3.4 /usr/local/hadoop}

\item Edit file hadoop-env.sh dengan mengubah variabel JAVA\_HOME\footnote{Pada baris 54, lebih jelasnya lihat Gambar \ref{gam:java-hadoop}} \\
{\tt cd /usr/local/hadoop} \\
{\tt sudo nano etc/hadoop/hadoop-env.sh} \\
\begin{lstlisting}
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
\end{lstlisting}

\begin{figure}[!ht]
\centering
\includegraphics[width=.6\textwidth]{java-hadoop}
\caption{Konfigurasi Java Home}
\label{gam:java-hadoop}
\end{figure}

\item Menambahkan Hadoop Path ke {\tt .bashrc}\footnote{Lebih jelasnya lihat Gambar \ref{gam:hadoop-path}} \\
{\tt sudo nano $\sim$/.bashrc} \\
\begin{lstlisting}
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export YARN_HOME=${HADOOP_HOME}
export PATH=$PATH:/usr/local/hadoop/bin
\end{lstlisting}

{\tt source .bashrc}
\begin{figure}[!ht]
\centering
\includegraphics[width=\textwidth]{hadoop-path}
\caption{Konfigurasi Hadoop Path}
\label{gam:hadoop-path}
\end{figure}

\item Verifikasi Hasil Instalasi Hadoop \\
{\tt hadoop version} \\
Jika instalasi hadoop sudah berhasil, maka ketika mengecek versi hadoop akan muncul seperti yang diperlihatkan pada Gambar \ref{gam:hadoop-version}.
\begin{figure}[!ht]
\includegraphics[width=\textwidth]{hadoop-version}
\caption{Versi Hadoop yang Terinstall}
\label{gam:hadoop-version}
\end{figure}
\end{enumerate}
 
\hrulefill

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newday{\#3 - 22 September 2022}
\textit{N.B.: Setiap mahasiswa membuat laporan hasil praktik sesuai dengan format yang telah ditentukan. Template laporan dapat di download pada alamat \url{https://github.com/muhdavi/laporan-practice-big-data}.}

\newthought{Konfigurasi Apache Hadoop}

Setelah selesai meng-install Hadoop, kita perlu konfigurasi beberapa file Hadoop agar memudahkan kita dalam memonitoring ekosistem Hadoop yang telah diinstall.

\begin{enumerate}
\item Konfigurasi File Hadoop \\
File-file konfigurasi hadoop berada pada folder {\tt hadoop/etc/hadoop} seperti yang diperlihatkan pada Gambar \ref{gam:file-hadoop}.
{\tt cd /usr/local/hadoop/etc/hadoop} \\
{\tt ls}
\begin{figure}[!ht]
\includegraphics[width=\textwidth]{file-hadoop}
\caption{File Konfigurasi Hadoop}
\label{gam:file-hadoop}
\end{figure}

Beberapa file yang perlu dikonfigurasi adalah sebebai berikut:
\begin{itemize}

\item core-site.xml
\begin{lstlisting}
<property>
	<name>fs.default.name</name>
	<value>hdfs://localhost:9000</value>
</property>
\end{lstlisting}
\begin{figure}[!ht]
\centering
\includegraphics[width=.8\textwidth]{site-core}
\caption{Konfigurasi Core Site}
\label{gam:site-yarn}
\end{figure}

\item hdfs-site.xml
\begin{lstlisting}
<property>
	<name>dfs.replication</name>
	<value>1</value>
</property>
<property>
	<name>dfs.permission</name>
	<value>false</value>
</property>
\end{lstlisting}
\begin{figure}[!ht]
\centering
\includegraphics[width=.7\textwidth]{site-hdfs}
\caption{Konfigurasi HDFS Site}
\label{gam:site-yarn}
\end{figure}

\item mapred-site.xml
\begin{lstlisting}
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>
\end{lstlisting}
\begin{figure}[!ht]
\includegraphics[width=\textwidth]{site-mapred}
\caption{Konfigurasi Mapred Site}
\label{gam:site-yarn}
\end{figure}

\item yarn-site.xml
\begin{lstlisting}
<property>
	<name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
</property>
<property>
	<name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
	<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
\end{lstlisting}
\begin{figure}[!ht]
\includegraphics[width=\textwidth]{site-yarn}
\caption{Konfigurasi Yarn Site}
\label{gam:site-yarn}
\end{figure}
\end{itemize}

\item Jalankan Perintah Format Filesystem \\
{\tt hdfs namenode -format}
\begin{figure}[!ht]
\includegraphics[width=\textwidth]{format-filesystem}
\caption{Format Filesystem}
\label{gam:format-filesystem}
\end{figure}

\item Jalankan NameNode Daemon dan DataNode Daemon \\
{\tt sbin/start-dfs.sh} \\
NameNode dapat diakses melalui \url{http://localhost:9870} dan akan tampil halaman web seperti yang diperlihatkan pada Gambar \ref{gam:namenode}.
\begin{figure}[!ht]
\includegraphics[width=\textwidth]{namenode}
\caption{Namemnode Hadoop}
\label{gam:namenode}
\end{figure}

\item Jalankan ResourceManager Daemon and NodeManager Daemon \\
{\tt sbin/start-yarn.sh} \\
ResourceManager dapat diakses melalui \url{http://localhost:8088} dan akan tampil halaman web serperti pada Gambar \ref{gam:namenode}.
\begin{figure}[!ht]
\includegraphics[width=\textwidth]{resourcemanager}
\caption{Resource Manager Hadoop}
\label{gam:resourcemanager}
\end{figure}
\end{enumerate}

Proses analisis big data sebaiknya menggunakan komputer dengan spesifikasi yang tinggi atau \textit{High Performance Computer (HPC)}. Namun jika tidak memiliki HPC cara lain adalah dengan menggabungkan beberapa komputer untuk melakukan proses analisis yang dikenal dengan nama \textit{Parallel Computing}. Paga Gambar \ref{gam:resourcemanager} terlihat bahwa ada 1 Node yang aktif, artinya jika diterapkan \textit{Parallel Computing} maka akan ada beberapa Node yang terhubung/aktif pada tampilan tersebut.

\hrulefill

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newday{\#4 - 24 November 2022 menggantikan 29 September 2022}

\newthought{Instalasi dan Konfigurasi GIT dan GitHub}

Pada pertemuan kali ini kita belajar install GIT dan konfigurasi GIT dengan GitHub agar dapat menjalankan perintah-perintah GIT melalui lokal dan menyimpan hasil kerjaan kita ke GitHub. Karena pada pertemuan pertama telah membuat akun GitHub, maka pada pertemuan kali ini asumsinya semua sudah memiliki akun GitHub. Setelah itu ikuti beberapa langkah berikut untuk praktikum kali ini.

\begin{enumerate}
\item Install Git \\
Pertema download program Git melalui link ini (\url{https://git-scm.com/download}) sesuai dengan sistem operasi yang digunakan. Bagi pengguna Windows jika proses download sudah selesai, lanjut proses instalasi seperti program windows pada umumnya (Next, Next, Next, sampai selesai).

\item \textit{Generate} SSH-Key \\
Jika instalasi sudah selesai, coba buka Git Bash, maka akan muncul program baru yang mirip dengan Terminal atau Command Prompt (CMD) kita sebut Git Bash. Kemudian jalankan perintah berikut untuk \textit{generate ssh-key}.

{\tt ssh-keygen -t ed25519 -C "email@akun.github"} \\

Ganti {\tt email@akun.github} dengan email yang terdaftar pada akun GitHub. Selanjutnya jika muncul beberapa pertanyaan seperti berikut ini tekan [enter].

{\tt > Enter a file in which to save the key (/Users/YOU/.ssh/id\_ed25519:} \\
{\tt > Enter passphrase (empty for no passphrase):} \\
{\tt > Enter same passphrase again:}

Jika proses diatas berhasil maka terbentuk folder baru dengan nama {\tt .ssh}. Didalam folder tersebut terdapat \textit{private key} dan \textit{public key}. Bukan file \textit{public key} (id\_ed25519.pub) dan \textit{copy} isi dari file tersebut.

\item Menambahkan SSH-Key ke Akun GitHub \\
Untuk menambahkan SSH-Key ke akun GitHub pertama login terlebih dahulu. Setelah berhasil login klik pada gambar profil sehingga tampil menu dropdown seperti pada Gambar \ref{gam:langkah-ssh} nomor 1. Selanjutnya pilih menu \textbf{Setting} sepertin yang ditunukan pada nomor 2. Setelah memilih menu \textbf{Setting} maka muncul halaman setting dengan menu di sidebar sebelah kiri. Pada menu sebelah kiri pilih menu \textbf{SSH and GPG keys} seperti pada nomor 3. Kemudian klik tombol \textbf{New SSH key} maka akan muncul form menambahkan SSH seperti yang diperlihatkan pada Gambar \ref{gam:form-ssh}.

\begin{figure}[!ht]
\includegraphics[width=\textwidth]{gtihub-1}
\caption{Lankah-langkah Menambah SSH-Key di GitHub}
\label{gam:langkah-ssh}
\end{figure}

Kode SSH-Key yang telah di-\textit{copy} pada langkah sebelumnya \textit{paste}-kan kode tersebut pada isian \textbf{Key} dan beri judul SSH-Key pada isian \textbf{Title}. Setelah semua diisi klik tombol \textbf{Add SSH key} untuk menyimpan SSH-Key baru tersebut.

\begin{figure}[!ht]
\includegraphics[width=\textwidth]{github-2}
\caption{Form Penambahan SSH-Key di GitHub}
\label{gam:form-ssh}
\end{figure}

Untuk menguji bahwa penambahan SSH-Key telah berhasil coba lakukan {\tt git push} untuk repositori laporan practice big data dari akun masing-masing. Untuk lebih jelasnya tentang GIT dapat membaca catatan pada link berikut \url{https://muhdavi.github.io/learn-git/}.
\end{enumerate}

\begin{figure}[!ht]
\includegraphics[width=.95\textwidth]{24-11-2022}
\caption{Perkuliahan Daring via GMeet 24-11-2022}
\label{gam:form-ssh}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newday{\#5 - 25 November 2022 menggantikan 6 Oktober 2022}

\newthought{Instalasi dan Konfigurasi GIT dan GitHub - Lanjutan}

Mahasiswa yang sudah berhasil konfigurasi Git dengan GitHub dan melalkukan {\tt Pull Request}:
\begin{multicols}{2}
\begin{enumerate}
\item Rizki Ilhami
\item Rauzatinur Syah $\star$
\item Taravia Fauzah
\item Resha Russita $\star$
\item Nurani Harum Fardaniah $\star$
\item Adinda Awaliah $\star$
\item Salsabila Irmanda $\star$
\item M. Ikhsan
\item Jihan Dwi Sarah $\star$
\item Cut Opy Mandalisa $\star$
\item Zulfahmi
\item Muhammad Munawir
\item Nuraula Tafiza
\item Muhammad Ikrammullah
\item Nadzura Kumaira
\end{enumerate}
\end{multicols}

\noindent
Berikut beberapa mahasiswa yang belum melakukan {\tt Pull Request}:
\begin{multicols}{2}
\begin{enumerate}
\item \textcolor{purple}{Adjie Yusmunandar}
\item Arya Saputra
\item Faiza Yuwafiqi
\item Nurul Aflah
\item \textcolor{red}{Siti Hajar Al Zahra}
\item Syarfani Akbar
\end{enumerate}
\end{multicols}

\begin{figure}[!ht]
\includegraphics[width=\textwidth]{25-11-2022}
\caption{Perkuliahan Daring via GMeet 25-11-2022}
\label{gam:form-ssh}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newday{\#6 - 1 Desember 2022 menggantikan 13 Oktober 2022}

\newthought{Instalasi Apache Pig}

\begin{enumerate}
\item Download Apache Pig  \\
Apache Pig dapat didownload dari link ini \url{https://downloads.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz} menggunakan {\tt wget} sehingga akan ada file baru dengan nama {\tt pig-0.17.0.tar.gz}

{\tt wget https://downloads.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz}

\item Ekstrak Apache Pig \\
Ekstrak hasil download tadi dengan perintah {\tt tar}

{\tt tar -xzvf pig-0.17.0.tar.gz}

\item Pindahkan Hasil Ekstraksi \\
Pindahkan hasil ekstraksi ke {\tt /usr/local/} dengan perintah {\tt mv}

{\tt sudo mv pig-0.17.0 /usr/local/pig}

\item Tambahkan Path Apache Pig ke {\tt .bashrc} \\
Untuk menambahkan path apache pig ke {\tt .bashrc} gunakan perintah nano

{\tt sudo nano $\sim$/.bashrc}

\begin{lstlisting}
#Apache Pig location
export PIG_INSTALL=/usr/local/pig
export PATH=$PATH:/usr/local/pig/bin
\end{lstlisting}

Kemdudian jalankan perintah {\tt source} agar konfigurasi yang telah ditambahkan ke {\tt .bashrc} dapat dikenali oleh sistem dan memastikan konfigurasi tersebut sudah benar.

{\tt source .bashrc}

\item Verifikasi Apache Pig \\
Untuk memverifikasi bahwa instalasi telah berhasil, coba cek versi Apache Pig dengan perintah berikut:

{\tt pig -version}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newday{\#7 - 2 Desember 2022 menggantikan 20 Oktober 2022}

\newthought{Instalasi Apache Hive}

\begin{enumerate}
\item Download Apaceh Hive \\
Download Apache Hive melalui link ini \url{https://downloads.apache.org/hive/stable-2/apache-hive-2.3.9-bin.tar.gz} dengan menggunakan perintah {\tt wget} seperti berikut:

{\tt wget https://downloads.apache.org/hive/stable-2/apache-hive-2.3.9-bin.tar.gz}

\item Ekstrak Apache Hive \\
Ekstrak file yang telah didownload dengna perintah berikut:

{\tt tar -zxvf apache-hive-2.3.9-bin.tar.gz}

\item Pindahkan Hasil Ekstraksi \\
Pindahkan hasil ekstraksi ke {\tt /usr/local/} dengan perintah {\tt mv}

{\tt sudo mv apache-hive-2.3.9-bin /usr/local/hive}

\item Tambahkan Path Apaceh Hive ke {\tt .bashrc} \\
Untuk menambahkan path apache hive ke {\tt .bashrc} gunakan perintah nano
seperti berikut:

{\tt sudo nano $\sim$/.bashrc}

\begin{lstlisting}
#Apache Hive location
export HIVE_HOME=/usr/local/hive
export PATH=$PATH:/usr/local/hive/bin
\end{lstlisting}

\item Konfigurasi {\tt core-site.xml} \\
Buka file {\tt core-site.xml} yang berada di {\tt /usr/local/hadoop/etc/hadoop} dan update seperti pada kode berikut:

\begin{lstlisting}
<configuration>
	<property>
		<name>fs.default.name</name>
		<value>hdfs://localhost:9000</value>
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/home/muhdavi/hadoop/tmp</value>
	</property>
	<property>
		<name>hadoop.proxyuser.dataflair.groups</name>
		<value>*</value>
	</property>
	<property>
		<name>hadoop.proxyuser.dataflair.hosts</name>
		<value>*</value>
	</property>
	<property>
		<name>hadoop.proxyuser.server.hosts</name>
		<value>*</value>
	</property>
	<property>
		<name>hadoop.proxyuser.server.groups</name>
		<value>*</value>
	</property>
</configuration>
\end{lstlisting}

\item Membuat directory di HDPS \\
Buatlah beberapa directory berikut di HDPS dengan perintah sebagai berikut:

{\tt \$hadoop fs -mkdir /tmp} \\
{\tt \$hadoop fs -mkdir /user} \\
{\tt \$hadoop fs -mkdir /user/hive} \\
{\tt \$hadoop fs -mkdir /user/hive/warehouse}

\item Memberikan Hak Akses \\
Memberikan hak akses (\textit{permission}) pada folder berikut:

{\tt \$hadoop fs -chmod g+w /tmp} \\
{\tt \$hadoop fs -chmod g+w /user/hive/warehouse}

\item Inisialisasi Hive Database

{\tt \$bin/schematool -dbType derby -initSchema}

\item Jalankan Hive

{\tt \$bin/hiveserver2}

\item Verifikasi Hive \\
Buka terminal baru dan coba konek ke Hive dengan perintah berikut:

{\tt \$bin/beeline -n bigdata -u jdbc:hive2://localhost:10000}

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newday{\#8 - 8 Desember 2022 menggantikan 3 November 2022}

\newthought{Analisis Data Youtube}

\begin{enumerate}
\item Download Dataset \\
Dataset dapat didownload dengan perintah berikut.

{\tt wget http://netsg.cs.sfu.ca/youtubedata/0222.zip}

\item Kode Apache Pig \\
Tulis kode Apache Pig berikut menggunakan IDE.

\begin{lstlisting}
infiles = load '/hdfs/bhavesh/Youtube_POC/Youtube/0222/{0,1,2,3,4}.txt' using PigStorage('\t') as 
(videoid:chararray,uploader:chararray,age:int,category:chararray,length:int,views:int,rate:int,rating:int,comments:int,related_id:chararray);
files = FILTER infiles BY category is not null;
grpn_for_catagories = group files by category;
cnt_for_catagories = foreach grpn_for_catagories generate group, COUNT(files.videoid) as counting;
sorted_for_catagories_desc = order cnt_for_catagories by counting desc;
top5_for_catagories = limit sorted_for_catagories_desc 5;
STORE top5_for_catagories INTO  '/hdfs/bhavesh/Youtube_POC/Top5Catagories' using PigStorage(',');
order_rated_video = order files by rating desc;
top10_rated_video = limit order_rated_video 10;
final_top10_rated_video = foreach top10_rated_video generate $0,$3,$7;
STORE final_top10_rated_video INTO '/hdfs/bhavesh/Youtube_POC/Top10Rated' using PigStorage(',');
order_viewed_video = order files by views desc;
top10_viewed_video = limit order_viewed_video 10;
final_top10_viewed_video = foreach top10_viewed_video generate $0,$3,$5;
STORE final_top10_viewed_video INTO '/hdfs/bhavesh/Youtube_POC/Top10Viewed' using PigStorage(',');
top10_rated_catagories = foreach grpn_for_catagories{
                           sorted = order files by rating desc;
                           top10 = limit sorted 10;
                           generate flatten(top10);
};
top10_rated_by_catagories = foreach top10_rated_catagories generate $0,$3,$7;
STORE top10_rated_by_catagories INTO '/hdfs/bhavesh/Youtube_POC/Top10RatedByCatagories' using PigStorage(',');
top10_viewed_catagories = foreach grpn_for_catagories{
                           sorted = order files by views desc;
                           top10 = limit sorted 10;
                           generate flatten(top10);
};
top10_viewed_by_catagories = foreach top10_viewed_catagories generate $0,$3,$5;
STORE top10_viewed_by_catagories INTO '/hdfs/bhavesh/Youtube_POC/Top10ViewedByCatagories' using PigStorage(',');
\end{lstlisting}

\item Kode Shell Script

\begin{lstlisting}
sudo rm -rf /var/lib/hive/metastore/metastore_db/*.lck
rm /home/mrinmoy/Downloads/POC/YoutubePOC/Top5Catagories.csv
rm /home/mrinmoy/Downloads/POC/YoutubePOC/Top10Rated.csv
rm /home/mrinmoy/Downloads/POC/YoutubePOC/Top10RatedByCatagories.csv
rm /home/mrinmoy/Downloads/POC/YoutubePOC/Top10Viewed.csv
rm /home/mrinmoy/Downloads/POC/YoutubePOC/Top10ViewedByCatagories.csv
hadoop fs -rmr /hdfs/bhavesh/Youtube_POC/Top5Catagories
hadoop fs -rmr /hdfs/bhavesh/Youtube_POC/Top10Rated
hadoop fs -rmr /hdfs/bhavesh/Youtube_POC/Top10RatedByCatagories
hadoop fs -rmr /hdfs/bhavesh/Youtube_POC/Top10Viewed
hadoop fs -rmr /hdfs/bhavesh/Youtube_POC/Top10ViewedByCatagories
pig /home/bhavesh/Youtube_POC/Youtube/0222/Youtube_data_analysis.pig
hadoop fs -get /hdfs/bhavesh/Youtube_POC/Top5Catagories/part-r-00000               /home/mrinmoy/Downloads/POC/YoutubePOC/Top5Catagories.csv
hadoop fs -get /hdfs/bhavesh/Youtube_POC/Top10Rated/part-r-00000                   /home/mrinmoy/Downloads/POC/YoutubePOC/Top10Rated.csv
hadoop fs -get /hdfs/bhavesh/Youtube_POC/Top10RatedByCatagories/part-r-00000       /home/mrinmoy/Downloads/POC/YoutubePOC/Top10RatedByCatagories.csv
hadoop fs -get /hdfs/bhavesh/Youtube_POC/Top10Viewed/part-r-00000                  /home/mrinmoy/Downloads/POC/YoutubePOC/Top10Viewed.csv
hadoop fs -get /hdfs/bhavesh/Youtube_POC/Top10ViewedByCatagories/part-r-00000      /home/mrinmoy/Downloads/POC/YoutubePOC/Top10ViewedByCatagories.csv
hive -e 'drop table if exists Top5CatagoriesTable';
hive -e 'drop table if exists Top10RatedTable';
hive -e 'drop table if exists Top10RatedByCatagoriesTable';
hive -e 'drop table if exists Top10ViewedTable';
hive -e 'drop table if exists Top10ViewedByCatagoriesTable';
hive -e "create external table Top5CatagoriesTable(Top5Catagory string, VideoCount int) row format delimited fields terminated by',' lines terminated by '\n' stored as textfile location '/hdfs/bhavesh/Youtube_POC/hive/Top5Catagories'";
hive -e "create external table Top10RatedTable(Videoid string,Catagory string,Rating int) row format delimited fields terminated by',' lines terminated by '\n' stored as textfile location '/hdfs/bhavesh/Youtube_POC/hive/Top10RatedTable'";
hive -e "create external table Top10RatedByCatagoriesTable(Videoid string,Catagory string,Rating int) row format delimited fields terminated by',' lines terminated by '\n' stored as textfile location '/hdfs/bhavesh/Youtube_POC/hive/Top10RatedByCatagoriesTable'";
hive -e "create external table Top10ViewedTable(Videoid string,Catagory string,Viewed_count int) row format delimited fields terminated by',' lines terminated by '\n' stored as textfile location '/hdfs/bhavesh/Youtube_POC/hive/Top10ViewedTable'";
hive -e "create external table Top10ViewedByCatagoriesTable(Videoid string,Catagory string,Viewed_count int) row format delimited fields terminated by',' lines terminated by '\n' stored as textfile location '/hdfs/bhavesh/Youtube_POC/hive/Top10ViewedByCatagoriesTable'";
hive -e "load data inpath '/hdfs/bhavesh/Youtube_POC/Top5Catagories/part-r-00000' overwrite into table Top5CatagoriesTable";
hive -e "load data inpath '/hdfs/bhavesh/Youtube_POC/Top10Rated/part-r-00000' overwrite into table Top10RatedTable";
hive -e "load data inpath '/hdfs/bhavesh/Youtube_POC/Top10RatedByCatagories/part-r-00000' overwrite into table Top10RatedByCatagoriesTable";
hive -e "load data inpath '/hdfs/bhavesh/Youtube_POC/Top10Viewed/part-r-00000' overwrite into table Top10ViewedTable";
hive -e "load data inpath '/hdfs/bhavesh/Youtube_POC/Top10ViewedByCatagories/part-r-00000' overwrite into table Top10ViewedByCatagoriesTable";
\end{lstlisting}

\item Jalankan Shell Script
\item Cek Hasil CSV
\item Cek Hasil Hive
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\include{laporan/AdindaAwaliah}
\include{laporan/AdjieYusmunandar}
\include{laporan/AryaSaputra}
\include{laporan/CutOpyMandalisa}
\include{laporan/FaizaYuwafiqi}
\include{laporan/JihanDwiSarah}
\include{laporan/MIkhsan}
\include{laporan/MuhammadIkrammullah}
\include{laporan/MuhammadMunawir}
\include{laporan/NadzuraKumaira}
\include{laporan/NuraniHarumFardaniah}
\include{laporan/NuraulaTafiza}
\include{laporan/NurulAflah}
\include{laporan/RauzatinurSyah}
\include{laporan/ReshaRussita}
\include{laporan/RizkiIlhami}
\include{laporan/SalsabilaIrmanda}
\include{laporan/SitiHajarAlZahra}
\include{laporan/SyarfaniAkbar}
\include{laporan/TaraviaFauzah}
\include{laporan/Zulfahmi}

\clearpage
\bibliographystyle{plain}
\bibliography{lab_notes}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
